{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.- Azure ML Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "from azure.mgmt.storage import StorageManagementClient\n",
    "\n",
    "from azure.storage.blob import BlobServiceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from the YAML file\n",
    "with open(\"../config.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Resource Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.mgmt.resource import ResourceManagementClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Credentials and params\n",
    "# subscription_id = config[\"azure\"][\"subscription_id\"]\n",
    "# credential = DefaultAzureCredential()\n",
    "# resource_client = ResourceManagementClient(credential, subscription_id)\n",
    "\n",
    "# # Create resource group\n",
    "# resource_group_name = \"satellite_object_detection_resource_group\"\n",
    "# location = \"eastus\"\n",
    "\n",
    "# resource_client.resource_groups.create_or_update(\n",
    "#     resource_group_name,\n",
    "#     {\"location\": location}\n",
    "# )\n",
    "# print(f\"Resource Group '{resource_group_name}' created in {location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_name = \"satellite_object_detection_workspace_ml\"\n",
    "\n",
    "# Create Workspace\n",
    "ws = Workspace.create(\n",
    "    name=workspace_name,\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group=resource_group_name,\n",
    "    location=location,\n",
    "    exist_ok=True\n",
    ")\n",
    "print(f\"Workspace '{workspace_name}' created or retrieved successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Compute Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.exceptions import ComputeTargetException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_name = \"gpu-cluster\"\n",
    "vm_size = \"Standard_NC6\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=compute_name)\n",
    "    print(f\"The cluster '{compute_name}' already exists\")\n",
    "except ComputeTargetException:\n",
    "    print(f\"Creating the cluster '{compute_name}'...\")\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=vm_size, max_nodes=4)\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, compute_config)\n",
    "    compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data to Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_data_path = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "datastore.upload(src_dir=local_data_path, target_path=\"object-detection-data\", overwrite=True)\n",
    "print(\"Data successfully uploaded to the datastore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Storage Account Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = StorageManagementClient(credential, subscription_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_storage_account_keys(storage_client, resource_group_name, account_name):\n",
    "    keys_response = storage_client.storage_accounts.list_keys(resource_group_name, account_name)\n",
    "    keys = {key.key_name: key.value for key in keys_response.keys}\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if storage_account_name:\n",
    "    storage_keys = get_storage_account_keys(storage_client, resource_group_name, storage_account_name)\n",
    "    print(\"Successfully retrieved the storage account keys.\")\n",
    "else:\n",
    "    print(\"Failed to create or retrieve the storage account.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone the Tensorflow Model Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/tensorflow/models.git ../external/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Github Tensorflow Model Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_files_to_blob(account_name, account_key, container_name, source_folder):\n",
    "    account_url = f\"https://{account_name}.blob.core.windows.net\"\n",
    "    blob_service_client = BlobServiceClient(account_url=account_url, credential=account_key)\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    \n",
    "    try:\n",
    "        container_client.create_container()\n",
    "        print(f\"Container '{container_name}' created.\")\n",
    "    except Exception as e:\n",
    "        if \"ContainerAlreadyExists\" in str(e):\n",
    "            print(f\"Container '{container_name}' already exists.\")\n",
    "        else:\n",
    "            print(f\"Error creating container: {e}\")\n",
    "\n",
    "    files_to_upload = [os.path.join(root, file) for root, dirs, files in os.walk(source_folder) for file in files]\n",
    "    progress_bar = tqdm(files_to_upload)\n",
    "\n",
    "    for file_path in progress_bar:\n",
    "        blob_path = os.path.relpath(file_path, start=source_folder)\n",
    "        blob_client = container_client.get_blob_client(blob_path)\n",
    "\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as data:\n",
    "                blob_client.upload_blob(data, overwrite=True)\n",
    "        except Exception as e:\n",
    "            progress_bar.set_description(f\"Failed {os.path.basename(file_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_name = storage_account_name\n",
    "account_key = storage_keys['key1']\n",
    "container_name = '<CONTAINER_NAME>'\n",
    "source_folder = '../external/'\n",
    "\n",
    "upload_files_to_blob(account_name, account_key, container_name, source_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Blob Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.entities import AzureBlobDatastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client = MLClient(credential, subscription_id, resource_group_name, workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datastore(datastore_name, account_name, container_name):\n",
    "    \"\"\"\n",
    "    Ensure a datastore exists in the Azure ML workspace. If it does not exist, create it.\n",
    "\n",
    "    Parameters:\n",
    "    - datastore_name: Name of the datastore to check or create.\n",
    "    - account_name: Azure storage account name associated with the datastore.\n",
    "    - container_name: Azure storage container name associated with the datastore.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the datastore already exists\n",
    "    try:\n",
    "        existing_datastore = ml_client.datastores.get(datastore_name)\n",
    "        print(f\"Datastore '{datastore_name}' already exists.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Datastore '{datastore_name}' not found. Creating new datastore.\")\n",
    "        # Create a new datastore if it does not exist\n",
    "        blob_datastore = AzureBlobDatastore(\n",
    "            name=datastore_name,\n",
    "            description=\"Datastore for storing training data and other blobs\",\n",
    "            account_name=account_name,\n",
    "            container_name=container_name,\n",
    "        )\n",
    "\n",
    "        # Register the datastore in the workspace\n",
    "        ml_client.datastores.create_or_update(blob_datastore)\n",
    "        print(f\"Datastore '{datastore_name}' has been created and registered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_name = \"<DATASTORE_NAME>\"\n",
    "\n",
    "create_datastore(datastore_name, storage_account_name, container_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment and Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment, BuildContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_verify_environment(environment_name, account_name, container_name, repository_name, repository_docker_file_path):\n",
    "\n",
    "    try:\n",
    "        existing_environment = ml_client.environments.get(name=environment_name)\n",
    "        print(f\"Environment '{environment_name}' already exists. No need to recreate.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Environment '{environment_name}' not found. Creating a new one.\")\n",
    "\n",
    "    blob_storage_path = f\"https://{account_name}.blob.core.windows.net/{container_name}/{repository_name}/\"\n",
    "    build_context = BuildContext(\n",
    "        dockerfile_path=repository_docker_file_path,\n",
    "        path=blob_storage_path\n",
    "    )\n",
    "\n",
    "    env_docker_context = Environment(\n",
    "        build=build_context,\n",
    "        name=environment_name,\n",
    "        description=\"Environment created from a Docker context.\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        created_env = ml_client.environments.create_or_update(env_docker_context)\n",
    "        print(f\"Environment '{created_env.name}' created.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create or update environment: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_name = 'models'\n",
    "repository_docker_file_path = \"research/object_detection/dockerfiles/tf2/Dockerfile\"\n",
    "environment_name = \"<ENVIRONMENT_NAME>\"\n",
    "create_and_verify_environment(environment_name, account_name, container_name, repository_name, repository_docker_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satellite-object-detection-azure-infra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
