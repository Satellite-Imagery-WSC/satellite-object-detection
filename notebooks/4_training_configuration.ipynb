{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.- Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import tarfile\n",
    "import re\n",
    "from git import Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, destination_folder, file_name):\n",
    "\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "    path_to_write = f\"{destination_folder}/{file_name}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        with open(path_to_write, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"File downloaded and saved to: {path_to_write}\")\n",
    "    else:\n",
    "        print(f\"Failed to download the file, status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model = 'ssd-mobilenet-v2-fpnlite-320'\n",
    "\n",
    "MODELS_CONFIG = {\n",
    "    'ssd-mobilenet-v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
    "        'base_pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n",
    "    },\n",
    "    'efficientdet-d0': {\n",
    "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
    "        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n",
    "    },\n",
    "    'ssd-mobilenet-v2-fpnlite-320': {\n",
    "        'model_name': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8',\n",
    "        'base_pipeline_file': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz',\n",
    "    },\n",
    "}\n",
    "\n",
    "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
    "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
    "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
    "destination_folder = \"../external/train_models\"\n",
    "model_file_name = f\"{chosen_model}.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file(download_tar, destination_folder, model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = tarfile.open(f\"{destination_folder}/{model_file_name}\")\n",
    "tar.extractall(path = destination_folder)\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Model Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_config = f\"https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/{model_name}.config\"\n",
    "config_file_name = f\"{model_name}.config\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file(url_config, destination_folder, config_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone Github Tensorflow Models Garden Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_repository(repo_url, local_dir):\n",
    "    # Create the local directory if it does not exist\n",
    "    if not os.path.exists(local_dir):\n",
    "        os.makedirs(local_dir)\n",
    "        print(f\"Directory '{local_dir}' created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{local_dir}' already exists.\")\n",
    "    \n",
    "    # Clone the repository into the specified directory\n",
    "    try:\n",
    "        print(f\"Cloning {repo_url} into {local_dir}\")\n",
    "        Repo.clone_from(repo_url, local_dir)\n",
    "        print(\"Repository successfully cloned.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to clone the repository: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '../src/' created.\n",
      "Cloning https://github.com/tensorflow/models.git into ../src/\n",
      "Repository successfully cloned.\n"
     ]
    }
   ],
   "source": [
    "# URL of the GitHub repository you want to clone\n",
    "repo_url = 'https://github.com/tensorflow/models.git'\n",
    "\n",
    "# Local path where you want to save the cloned repository\n",
    "train_code = '../src/'\n",
    "\n",
    "# Execute the function\n",
    "clone_repository(repo_url, train_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 40000\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file locations and get number of classes for config file\n",
    "pipeline_fname = destination_folder + '/' + base_pipeline_file\n",
    "fine_tune_checkpoint = destination_folder + '/' + model_name + '/checkpoint/ckpt-0'\n",
    "num_classes = 1\n",
    "\n",
    "train_record_fname = '/content/train.tfrecord'\n",
    "val_record_fname = '/content/val.tfrecord'\n",
    "label_map_pbtxt_fname = '/content/labelmap.pbtxt'\n",
    "model_dir = '/content/training/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing custom configuration file\n"
     ]
    }
   ],
   "source": [
    "print('writing custom configuration file')\n",
    "\n",
    "with open(pipeline_fname) as f:\n",
    "    s = f.read()\n",
    "with open(f\"{train_code}/custom_pipeline_file.config\", 'w') as f:\n",
    "\n",
    "    # Set fine_tune_checkpoint path\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
    "\n",
    "    # Set tfrecord files for train and test datasets\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(val_record_fname), s)\n",
    "\n",
    "    # Set label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
    "\n",
    "    # Set batch_size\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(batch_size), s)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(num_steps), s)\n",
    "\n",
    "    # Set number of classes num_classes\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               'num_classes: {}'.format(num_classes), s)\n",
    "\n",
    "    # Change fine-tune checkpoint type from \"classification\" to \"detection\"\n",
    "    s = re.sub(\n",
    "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
    "\n",
    "    # If using ssd-mobilenet-v2, reduce learning rate (because it's too high in the default config file)\n",
    "    if chosen_model == 'ssd-mobilenet-v2':\n",
    "      s = re.sub('learning_rate_base: .8',\n",
    "                 'learning_rate_base: .08', s)\n",
    "\n",
    "      s = re.sub('warmup_learning_rate: 0.13333',\n",
    "                 'warmup_learning_rate: .026666', s)\n",
    "\n",
    "    # If using efficientdet-d0, use fixed_shape_resizer instead of keep_aspect_ratio_resizer (because it isn't supported by TFLite)\n",
    "    if chosen_model == 'efficientdet-d0':\n",
    "      s = re.sub('keep_aspect_ratio_resizer', 'fixed_shape_resizer', s)\n",
    "      s = re.sub('pad_to_max_dimension: true', '', s)\n",
    "      s = re.sub('min_dimension', 'height', s)\n",
    "      s = re.sub('max_dimension', 'width', s)\n",
    "\n",
    "    f.write(s)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satellite-object-detection-train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
