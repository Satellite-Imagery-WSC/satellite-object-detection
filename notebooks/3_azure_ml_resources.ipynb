{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.- Azure ML Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "from azure.mgmt.resource import ResourceManagementClient\n",
    "\n",
    "from azure.core.exceptions import ResourceExistsError, ResourceNotFoundError, HttpResponseError\n",
    "\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import Workspace\n",
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "from azure.mgmt.storage import StorageManagementClient\n",
    "\n",
    "from azure.storage.blob import BlobServiceClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from the YAML file\n",
    "with open(\"../config.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = config[\"azure\"][\"subscription_id\"]\n",
    "resource_group_name = config[\"azure\"][\"resource_group_name\"]\n",
    "workspace_name = config[\"azure\"][\"workspace_name\"]\n",
    "location = config[\"azure\"][\"location\"]\n",
    "# acr_name = config[\"azure\"][\"acr_name\"]\n",
    "# sku = config[\"azure\"][\"sku\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DefaultAzureCredential\n",
    "credential = DefaultAzureCredential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resource Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Resource Management client\n",
    "resource_client = ResourceManagementClient(credential, subscription_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resource_group(resource_client, resource_group_name, location):\n",
    "    try:\n",
    "        # Intenta obtener el grupo de recursos\n",
    "        resource_group = resource_client.resource_groups.get(resource_group_name)\n",
    "        print(f\"Resource Group '{resource_group_name}' already exists in '{resource_group.location}'.\")\n",
    "    except ResourceNotFoundError:\n",
    "        # Si el grupo de recursos no existe, cr√©alo\n",
    "        resource_group_params = {\"location\": location}\n",
    "        resource_group = resource_client.resource_groups.create_or_update(\n",
    "            resource_group_name,\n",
    "            resource_group_params\n",
    "        )\n",
    "        print(f\"Resource Group '{resource_group_name}' created in '{resource_group.location}'.\")\n",
    "    except Exception as e:\n",
    "        # Maneja otras excepciones\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "    return resource_group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource Group 'test_group' already exists in 'eastus'.\n"
     ]
    }
   ],
   "source": [
    "# Call the function to create the Resource Group\n",
    "resource_group = create_resource_group(resource_client, resource_group_name, location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client = MLClient(credential, subscription_id, resource_group_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import Workspace\n",
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "\n",
    "def create_workspace(ml_client, workspace_name, location):\n",
    "    try:\n",
    "        # Try to get the existing Workspace\n",
    "        workspace = ml_client.workspaces.get(workspace_name)\n",
    "        print(f\"Workspace '{workspace_name}' already exists in '{workspace.location}'.\")\n",
    "        return workspace\n",
    "    except ResourceNotFoundError:\n",
    "        # If the Workspace does not exist, create it asynchronously\n",
    "        workspace_poller = ml_client.workspaces.begin_create(\n",
    "            Workspace(\n",
    "                name=workspace_name,\n",
    "                location=location  # Use the 'location' variable\n",
    "            )\n",
    "        )\n",
    "        workspace = workspace_poller.result()  # Wait for the operation to complete\n",
    "        print(f\"Workspace '{workspace_name}' created in '{workspace.location}'.\")\n",
    "        return workspace\n",
    "    except Exception as e:\n",
    "        # Handle other exceptions\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace 'machine_que_tal' already exists in 'eastus'.\n"
     ]
    }
   ],
   "source": [
    "workspace = create_workspace(ml_client, workspace_name, location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Woskspace Storage Account Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machineqstoragef44501b0a'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage_account_name = workspace.storage_account.split('/')[-1]\n",
    "storage_account_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Storage Account Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = StorageManagementClient(credential, subscription_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_storage_account_keys(storage_client, resource_group_name, account_name):\n",
    "    keys_response = storage_client.storage_accounts.list_keys(resource_group_name, account_name)\n",
    "    keys = {key.key_name: key.value for key in keys_response.keys}\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved the storage account keys.\n"
     ]
    }
   ],
   "source": [
    "if storage_account_name:\n",
    "    storage_keys = get_storage_account_keys(storage_client, resource_group_name, storage_account_name)\n",
    "    print(\"Successfully retrieved the storage account keys.\")\n",
    "else:\n",
    "    print(\"Failed to create or retrieve the storage account.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone the Tensorflow Model Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '../external/models'...\n",
      "Updating files:  22% (861/3884)\n",
      "Updating files:  23% (894/3884)\n",
      "Updating files:  24% (933/3884)\n",
      "Updating files:  25% (971/3884)\n",
      "Updating files:  26% (1010/3884)\n",
      "Updating files:  27% (1049/3884)\n",
      "Updating files:  28% (1088/3884)\n",
      "Updating files:  29% (1127/3884)\n",
      "Updating files:  30% (1166/3884)\n",
      "Updating files:  31% (1205/3884)\n",
      "Updating files:  32% (1243/3884)\n",
      "Updating files:  33% (1282/3884)\n",
      "Updating files:  34% (1321/3884)\n",
      "Updating files:  35% (1360/3884)\n",
      "Updating files:  36% (1399/3884)\n",
      "Updating files:  37% (1438/3884)\n",
      "Updating files:  38% (1476/3884)\n",
      "Updating files:  39% (1515/3884)\n",
      "Updating files:  40% (1554/3884)\n",
      "Updating files:  40% (1577/3884)\n",
      "Updating files:  41% (1593/3884)\n",
      "Updating files:  42% (1632/3884)\n",
      "error: unable to create file official/projects/waste_identification_ml/circularnet-docs/themes/hugo-theme-techdoc/src/js/jquery.backtothetop/jquery.backtothetop.min.js: Filename too long\n",
      "Updating files:  43% (1671/3884)\n",
      "Updating files:  44% (1709/3884)\n",
      "Updating files:  45% (1748/3884)\n",
      "Updating files:  46% (1787/3884)\n",
      "Updating files:  47% (1826/3884)\n",
      "Updating files:  48% (1865/3884)\n",
      "Updating files:  49% (1904/3884)\n",
      "Updating files:  50% (1942/3884)\n",
      "Updating files:  51% (1981/3884)\n",
      "Updating files:  52% (2020/3884)\n",
      "Updating files:  53% (2059/3884)\n",
      "Updating files:  54% (2098/3884)\n",
      "Updating files:  55% (2137/3884)\n",
      "Updating files:  55% (2152/3884)\n",
      "Updating files:  56% (2176/3884)\n",
      "Updating files:  57% (2214/3884)\n",
      "Updating files:  58% (2253/3884)\n",
      "Updating files:  59% (2292/3884)\n",
      "Updating files:  60% (2331/3884)\n",
      "Updating files:  61% (2370/3884)\n",
      "Updating files:  62% (2409/3884)\n",
      "Updating files:  63% (2447/3884)\n",
      "Updating files:  64% (2486/3884)\n",
      "Updating files:  65% (2525/3884)\n",
      "Updating files:  66% (2564/3884)\n",
      "Updating files:  67% (2603/3884)\n",
      "Updating files:  68% (2642/3884)\n",
      "Updating files:  69% (2680/3884)\n",
      "Updating files:  70% (2719/3884)\n",
      "Updating files:  71% (2758/3884)\n",
      "Updating files:  72% (2797/3884)\n",
      "Updating files:  73% (2836/3884)\n",
      "Updating files:  73% (2859/3884)\n",
      "Updating files:  74% (2875/3884)\n",
      "Updating files:  75% (2913/3884)\n",
      "Updating files:  76% (2952/3884)\n",
      "Updating files:  77% (2991/3884)\n",
      "Updating files:  78% (3030/3884)\n",
      "Updating files:  79% (3069/3884)\n",
      "Updating files:  80% (3108/3884)\n",
      "Updating files:  81% (3147/3884)\n",
      "Updating files:  82% (3185/3884)\n",
      "Updating files:  83% (3224/3884)\n",
      "Updating files:  84% (3263/3884)\n",
      "Updating files:  85% (3302/3884)\n",
      "Updating files:  86% (3341/3884)\n",
      "Updating files:  86% (3364/3884)\n",
      "Updating files:  87% (3380/3884)\n",
      "Updating files:  88% (3418/3884)\n",
      "error: unable to create file research/object_detection/samples/configs/ssd_mobilenet_v2_fpnlite_quantized_shared_box_predictor_256x256_depthmultiplier_75_coco14_sync.config: Filename too long\n",
      "Updating files:  89% (3457/3884)\n",
      "Updating files:  90% (3496/3884)\n",
      "Updating files:  91% (3535/3884)\n",
      "Updating files:  92% (3574/3884)\n",
      "Updating files:  93% (3613/3884)\n",
      "Updating files:  94% (3651/3884)\n",
      "Updating files:  95% (3690/3884)\n",
      "Updating files:  96% (3729/3884)\n",
      "Updating files:  97% (3768/3884)\n",
      "Updating files:  98% (3807/3884)\n",
      "Updating files:  99% (3846/3884)\n",
      "Updating files: 100% (3884/3884)\n",
      "Updating files: 100% (3884/3884), done.\n",
      "fatal: unable to checkout working tree\n",
      "warning: Clone succeeded, but checkout failed.\n",
      "You can inspect what was checked out with 'git status'\n",
      "and retry with 'git restore --source=HEAD :/'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tensorflow/models.git ../external/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Github Tensorflow Model Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_files_to_blob(account_name, account_key, container_name, source_folder):\n",
    "    account_url = f\"https://{account_name}.blob.core.windows.net\"\n",
    "    blob_service_client = BlobServiceClient(account_url=account_url, credential=account_key)\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    \n",
    "    try:\n",
    "        container_client.create_container()\n",
    "        print(f\"Container '{container_name}' created.\")\n",
    "    except Exception as e:\n",
    "        if \"ContainerAlreadyExists\" in str(e):\n",
    "            print(f\"Container '{container_name}' already exists.\")\n",
    "        else:\n",
    "            print(f\"Error creating container: {e}\")\n",
    "\n",
    "    files_to_upload = [os.path.join(root, file) for root, dirs, files in os.walk(source_folder) for file in files]\n",
    "    progress_bar = tqdm(files_to_upload)\n",
    "\n",
    "    for file_path in progress_bar:\n",
    "        blob_path = os.path.relpath(file_path, start=source_folder)\n",
    "        blob_client = container_client.get_blob_client(blob_path)\n",
    "\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as data:\n",
    "                blob_client.upload_blob(data, overwrite=True)\n",
    "        except Exception as e:\n",
    "            progress_bar.set_description(f\"Failed {os.path.basename(file_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container 'containerml171717' already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3907/3907 [06:40<00:00,  9.76it/s]\n"
     ]
    }
   ],
   "source": [
    "account_name = storage_account_name\n",
    "account_key = storage_keys['key1']\n",
    "container_name = 'containerml171717'\n",
    "source_folder = '../external/'\n",
    "\n",
    "upload_files_to_blob(account_name, account_key, container_name, source_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Blob Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.entities import AzureBlobDatastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client = MLClient(credential, subscription_id, resource_group_name, workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current LoggerProvider is not allowed\n",
      "Overriding of current MeterProvider is not allowed\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to register datastore: (InvalidApiVersionParameter) The api-version '2024-07-01-preview' is invalid. The supported versions are '2024-11-01,2024-08-01,2024-07-01,2024-06-01-preview,2024-03-01,2023-07-01,2023-07-01-preview,2023-03-01-preview,2022-12-01,2022-11-01-preview,2022-09-01,2022-06-01,2022-05-01,2022-03-01-preview,2022-01-01,2021-04-01,2021-01-01,2020-10-01,2020-09-01,2020-08-01,2020-07-01,2020-06-01,2020-05-01,2020-01-01,2019-11-01,2019-10-01,2019-09-01,2019-08-01,2019-07-01,2019-06-01,2019-05-10,2019-05-01,2019-03-01,2018-11-01,2018-09-01,2018-08-01,2018-07-01,2018-06-01,2018-05-01,2018-02-01,2018-01-01,2017-12-01,2017-08-01,2017-06-01,2017-05-10,2017-05-01,2017-03-01,2016-09-01,2016-07-01,2016-06-01,2016-02-01,2015-11-01,2015-01-01,2014-04-01-preview,2014-04-01,2014-01-01,2013-03-01,2014-02-26,2014-04'.\n",
      "Code: InvalidApiVersionParameter\n",
      "Message: The api-version '2024-07-01-preview' is invalid. The supported versions are '2024-11-01,2024-08-01,2024-07-01,2024-06-01-preview,2024-03-01,2023-07-01,2023-07-01-preview,2023-03-01-preview,2022-12-01,2022-11-01-preview,2022-09-01,2022-06-01,2022-05-01,2022-03-01-preview,2022-01-01,2021-04-01,2021-01-01,2020-10-01,2020-09-01,2020-08-01,2020-07-01,2020-06-01,2020-05-01,2020-01-01,2019-11-01,2019-10-01,2019-09-01,2019-08-01,2019-07-01,2019-06-01,2019-05-10,2019-05-01,2019-03-01,2018-11-01,2018-09-01,2018-08-01,2018-07-01,2018-06-01,2018-05-01,2018-02-01,2018-01-01,2017-12-01,2017-08-01,2017-06-01,2017-05-10,2017-05-01,2017-03-01,2016-09-01,2016-07-01,2016-06-01,2016-02-01,2015-11-01,2015-01-01,2014-04-01-preview,2014-04-01,2014-01-01,2013-03-01,2014-02-26,2014-04'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Check if the datastore already exists\n",
    "try:\n",
    "    existing_datastore = ml_client.datastores.get(datastore_name)\n",
    "    print(f\"Datastore '{datastore_name}' already exists.\")\n",
    "except Exception as e:\n",
    "    print(f\"Datastore '{datastore_name}' not found. Creating new datastore.\")\n",
    "    # Create a new datastore if it does not exist\n",
    "    blob_datastore = AzureBlobDatastore(\n",
    "        name=datastore_name,\n",
    "        description=\"Datastore for storing training data and other blobs\",\n",
    "        account_name=storage_account_name,\n",
    "        container_name=container_name,\n",
    "    )\n",
    "\n",
    "    # Register the datastore in the workspace\n",
    "    ml_client.datastores.create_or_update(blob_datastore)\n",
    "    print(f\"Datastore '{datastore_name}' has been created and registered.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client = MLClient(credential, subscription_id, resource_group, workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machine_que_tal'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current LoggerProvider is not allowed\n",
      "Overriding of current MeterProvider is not allowed\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n"
     ]
    }
   ],
   "source": [
    "ml_client = MLClient(credential, subscription_id, resource_group_name, workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un datastore que apunta al contenedor de Blob Storage donde est√° tu repositorio\n",
    "blob_datastore = AzureBlobDatastore(\n",
    "    name=\"my_blob_datastore_QUETAL\",\n",
    "    description=\"Datastore for storing training data and other blobs\",\n",
    "    account_name=storage_account_name,  # Nombre de la cuenta de almacenamiento\n",
    "    container_name=container_name      # Nombre del contenedor donde se subi√≥ el repositorio\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AzureBlobDatastore({'type': <DatastoreType.AZURE_BLOB: 'AzureBlob'>, 'name': 'my_blob_datastore_quetal', 'description': 'Datastore for storing training data and other blobs', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/6f68d13a-dffb-46b3-acb9-1630e75d6a0a/resourceGroups/test_group/providers/Microsoft.MachineLearningServices/workspaces/machine_que_tal/datastores/my_blob_datastore_quetal', 'Resource__source_path': '', 'base_path': 'c:\\\\Users\\\\walte\\\\Documents\\\\Projects\\\\GitHub\\\\My_Organizations\\\\Satellite-Imagery-WSC\\\\satellite-object-detection\\\\notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000017E74F691C0>, 'credentials': <azure.ai.ml.entities._credentials.NoneCredentialConfiguration object at 0x0000017E77BAF7F0>, 'container_name': 'containerml171717', 'account_name': 'machineqstoragef44501b0a', 'endpoint': 'core.windows.net', 'protocol': 'https'})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.create_or_update(blob_datastore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satellite-object-detection-azure-infra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
