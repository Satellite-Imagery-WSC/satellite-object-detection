{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.- Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_voc_xml(xml_path):\n",
    "    \"\"\"\n",
    "    Parses a Pascal VOC XML file and returns a dictionary with:\n",
    "    {\n",
    "      'filename': 'image_name.jpg',\n",
    "      'width': 1280,\n",
    "      'height': 720,\n",
    "      'objects': [\n",
    "        {\n",
    "          'name': 'dog',\n",
    "          'xmin': 50, 'ymin': 30, 'xmax': 150, 'ymax': 100\n",
    "        },\n",
    "        ...\n",
    "      ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    data = {}\n",
    "    data['objects'] = []\n",
    "\n",
    "    # filename tag\n",
    "    filename_node = root.find('filename')\n",
    "    data['filename'] = filename_node.text if filename_node is not None else None\n",
    "\n",
    "    # size tag (width, height)\n",
    "    size_node = root.find('size')\n",
    "    if size_node is not None:\n",
    "        w_node = size_node.find('width')\n",
    "        h_node = size_node.find('height')\n",
    "        data['width'] = int(w_node.text) if w_node is not None else 0\n",
    "        data['height'] = int(h_node.text) if h_node is not None else 0\n",
    "    else:\n",
    "        data['width'] = 0\n",
    "        data['height'] = 0\n",
    "\n",
    "    # object tags\n",
    "    for obj_node in root.findall('object'):\n",
    "        obj_info = {}\n",
    "        name_node = obj_node.find('name')\n",
    "        obj_info['name'] = name_node.text if name_node is not None else \"N/A\"\n",
    "\n",
    "        # bounding box\n",
    "        bndbox_node = obj_node.find('bndbox')\n",
    "        if bndbox_node is not None:\n",
    "            xmin_node = bndbox_node.find('xmin')\n",
    "            ymin_node = bndbox_node.find('ymin')\n",
    "            xmax_node = bndbox_node.find('xmax')\n",
    "            ymax_node = bndbox_node.find('ymax')\n",
    "\n",
    "            obj_info['xmin'] = float(xmin_node.text) if xmin_node is not None else 0\n",
    "            obj_info['ymin'] = float(ymin_node.text) if ymin_node is not None else 0\n",
    "            obj_info['xmax'] = float(xmax_node.text) if xmax_node is not None else 0\n",
    "            obj_info['ymax'] = float(ymax_node.text) if ymax_node is not None else 0\n",
    "\n",
    "        data['objects'].append(obj_info)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Converts a byte string into a tf.train.Feature of bytes_list.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _float_list_feature(value):\n",
    "    \"\"\"Converts a float list into a tf.train.Feature of float_list.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Converts an integer value into a tf.train.Feature of int64_list.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def _int64_list_feature(value):\n",
    "    \"\"\"Converts a list of integers into a tf.train.Feature of int64_list.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voc_dict_to_tfexample(voc_dict, images_folder):\n",
    "    \"\"\"\n",
    "    Takes the dictionary output by parse_voc_xml(xml_file)\n",
    "    along with the folder containing images (images_folder).\n",
    "    \n",
    "    Returns a tf.train.Example with:\n",
    "    - image/encoded\n",
    "    - image/filename\n",
    "    - image/height, image/width\n",
    "    - image/object/bbox/xmin, xmax, ymin, ymax\n",
    "    - image/object/class/text\n",
    "    \"\"\"\n",
    "\n",
    "    filename = voc_dict['filename']\n",
    "    if filename is None:\n",
    "        # If <filename> is missing in the XML, we skip\n",
    "        return None\n",
    "\n",
    "    img_path = os.path.join(images_folder, filename)\n",
    "    if not os.path.isfile(img_path):\n",
    "        # If the image does not exist in JPEGImages folder, skip\n",
    "        return None\n",
    "\n",
    "    # Read the image in binary\n",
    "    with tf.io.gfile.GFile(img_path, 'rb') as fid:\n",
    "        encoded_image = fid.read()\n",
    "\n",
    "    width = voc_dict['width']\n",
    "    height = voc_dict['height']\n",
    "\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    class_texts = []\n",
    "\n",
    "    for obj in voc_dict['objects']:\n",
    "        if width > 0 and height > 0:\n",
    "            xmins.append(obj['xmin'] / width)\n",
    "            xmaxs.append(obj['xmax'] / width)\n",
    "            ymins.append(obj['ymin'] / height)\n",
    "            ymaxs.append(obj['ymax'] / height)\n",
    "        else:\n",
    "            # Avoid zero-division if the XML lacks <size> data\n",
    "            xmins.append(0.0)\n",
    "            xmaxs.append(0.0)\n",
    "            ymins.append(0.0)\n",
    "            ymaxs.append(0.0)\n",
    "\n",
    "        # The class name is stored as text (string)\n",
    "        class_texts.append(obj['name'].encode('utf8'))\n",
    "\n",
    "    feature_dict = {\n",
    "        'image/encoded': _bytes_feature(encoded_image),\n",
    "        'image/filename': _bytes_feature(filename.encode('utf8')),\n",
    "        'image/format': _bytes_feature(b'jpg'),\n",
    "\n",
    "        'image/height': _int64_feature(height),\n",
    "        'image/width': _int64_feature(width),\n",
    "\n",
    "        'image/object/bbox/xmin': _float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': _float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': _float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': _float_list_feature(ymaxs),\n",
    "\n",
    "        # We store class text; you could also map it to class IDs if needed\n",
    "        'image/object/class/text':\n",
    "            tf.train.Feature(bytes_list=tf.train.BytesList(value=class_texts)),\n",
    "    }\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_voc_to_tfrecord(annotations_folder, images_folder, output_tfrecord):\n",
    "    \"\"\"\n",
    "    Reads all .xml files from 'annotations_folder', pairs them\n",
    "    with images in 'images_folder', and writes a TFRecord to\n",
    "    'output_tfrecord'.\n",
    "\n",
    "    Returns the number of successfully written examples and\n",
    "    the number of errors (e.g. missing files).\n",
    "    \"\"\"\n",
    "\n",
    "    xml_files = glob.glob(os.path.join(annotations_folder, \"*.xml\"))\n",
    "    num_written = 0\n",
    "    num_errors = 0\n",
    "\n",
    "    with tf.io.TFRecordWriter(output_tfrecord) as writer:\n",
    "        for xml_file in xml_files:\n",
    "            voc_info = parse_voc_xml(xml_file)\n",
    "            tf_example = voc_dict_to_tfexample(voc_info, images_folder)\n",
    "            if tf_example is not None:\n",
    "                writer.write(tf_example.SerializeToString())\n",
    "                num_written += 1\n",
    "            else:\n",
    "                num_errors += 1\n",
    "\n",
    "    return num_written, num_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion done. Written: 20, Errors: 0\n",
      "TFRecord created at: voc_train.record\n"
     ]
    }
   ],
   "source": [
    "# Adjust these to your actual dataset paths\n",
    "annotations_dir = \"../data/Annotations\"\n",
    "images_dir = \"../data/JPEGImages\"\n",
    "output_record = \"voc_train.record\"\n",
    "\n",
    "written, errors = convert_voc_to_tfrecord(\n",
    "    annotations_folder=annotations_dir,\n",
    "    images_folder=images_dir,\n",
    "    output_tfrecord=output_record\n",
    ")\n",
    "\n",
    "print(f\"Conversion done. Written: {written}, Errors: {errors}\")\n",
    "print(f\"TFRecord created at: {output_record}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satellite-object-detection-preprocessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
