{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.- Data Transformation - TFRecords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Use TFRecord for Object Detection Models\n",
    "\n",
    "When preparing datasets for training machine learning models, especially in the realm of **object detection**, choosing the right data format is crucial for optimizing performance and ensuring seamless integration with training pipelines. **TFRecord** stands out as the preferred format within the **TensorFlow** ecosystem. Below are the key reasons why TFRecord is advantageous for object detection tasks:\n",
    "\n",
    "\n",
    "### 1. **Efficiency and Performance**\n",
    "\n",
    "- **Binary Format**: TFRecord stores data in a compact binary format, which is significantly faster to read and write compared to traditional formats like CSV or JSON. This efficiency is vital when dealing with large datasets containing millions of images.\n",
    "\n",
    "- **Sequential Access**: Data stored in TFRecord files can be accessed sequentially, which aligns well with the way TensorFlow processes data during training. This minimizes the overhead associated with random file reads, enhancing the overall training speed.\n",
    "\n",
    "\n",
    "\n",
    "### 2. **Seamless Integration with TensorFlow Pipelines**\n",
    "\n",
    "- **`tf.data` API Compatibility**: TFRecord is natively supported by TensorFlow's `tf.data` API, allowing for straightforward data ingestion, preprocessing, and batching. This compatibility ensures that data loading becomes an integral and optimized part of the training pipeline.\n",
    "\n",
    "- **Parallel Data Processing**: Leveraging TFRecord in combination with the `tf.data` API enables parallel data loading and preprocessing. This parallelism is essential for maximizing GPU/TPU utilization and reducing training times.\n",
    "\n",
    "\n",
    "\n",
    "### 3. **Scalability for Large Datasets**\n",
    "\n",
    "- **Handling Massive Data**: Object detection tasks often require handling extensive datasets with high-resolution images and numerous annotations. TFRecord efficiently manages such large-scale data without significant performance degradation.\n",
    "\n",
    "- **Sharding Capability**: TFRecord allows datasets to be split into multiple shards (smaller TFRecord files). Sharding facilitates distributed training and makes it easier to manage and access data across different storage systems or machines.\n",
    "\n",
    "\n",
    "\n",
    "### 4. **Reduced I/O Overhead**\n",
    "\n",
    "- **Minimized File Operations**: Instead of reading thousands of individual image files and annotation files, TFRecord consolidates all data into fewer large files. This reduction in the number of file operations decreases the I/O overhead, leading to faster data access and improved training throughput.\n",
    "\n",
    "\n",
    "\n",
    "### 5. **Data Serialization and Consistency**\n",
    "\n",
    "- **Structured Data Storage**: TFRecord, in conjunction with `tf.train.Example`, allows for the structured serialization of complex data types, including images, bounding boxes, and class labels. This structure ensures consistency in how data is stored and accessed, reducing potential errors during training.\n",
    "\n",
    "- **Custom Feature Encoding**: With TFRecord, you can define custom features tailored to your specific needs, such as storing multiple bounding boxes per image or incorporating additional metadata. This flexibility is crucial for accommodating the diverse requirements of object detection models.\n",
    "\n",
    "\n",
    "\n",
    "### 6. **Enhanced Portability and Reproducibility**\n",
    "\n",
    "- **Cross-Platform Compatibility**: TFRecord files are platform-agnostic, meaning they can be easily shared and used across different environments without compatibility issues. This portability is beneficial for collaborative projects and reproducible research.\n",
    "\n",
    "- **Version Control Friendly**: Storing data in TFRecord format facilitates better version control practices, especially when dealing with evolving datasets and model iterations.\n",
    "\n",
    "\n",
    "\n",
    "### 7. **Optimized for Distributed Training**\n",
    "\n",
    "- **Distributed Systems Support**: TFRecord is optimized for use in distributed training environments, where data needs to be efficiently fed to multiple workers or nodes. Its binary format and sharding capabilities make it ideal for scaling training across clusters.\n",
    "\n",
    "- **Consistency Across Workers**: By using TFRecord, you ensure that all training workers access the data in a consistent and synchronized manner, which is essential for maintaining model performance and convergence during distributed training.\n",
    "\n",
    "\n",
    "\n",
    "### 8. **Security and Data Integrity**\n",
    "\n",
    "- **Data Integrity**: TFRecord's structured binary format reduces the risk of data corruption compared to plain text formats. This integrity is crucial for maintaining the quality and reliability of your training data.\n",
    "\n",
    "- **Obfuscation**: Storing data in a binary format also provides a layer of obfuscation, making it less accessible for unauthorized users to tamper with the dataset compared to easily readable text formats.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_voc_xml(xml_path):\n",
    "    \"\"\"\n",
    "    Parses a Pascal VOC XML file and returns a dictionary with:\n",
    "    {\n",
    "      'filename': 'image_name.jpg',\n",
    "      'width': 1280,\n",
    "      'height': 720,\n",
    "      'objects': [\n",
    "        {\n",
    "          'name': 'dog',\n",
    "          'xmin': 50, 'ymin': 30, 'xmax': 150, 'ymax': 100\n",
    "        },\n",
    "        ...\n",
    "      ]\n",
    "    }\n",
    "    \n",
    "    Args:\n",
    "        xml_path (str): Path to the XML annotation file.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Parsed data from the XML file.\n",
    "    \"\"\"\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    data = {}\n",
    "    data['objects'] = []\n",
    "\n",
    "    # Extract the filename\n",
    "    filename_node = root.find('filename')\n",
    "    data['filename'] = filename_node.text if filename_node is not None else None\n",
    "\n",
    "    # Extract image size (width and height)\n",
    "    size_node = root.find('size')\n",
    "    if size_node is not None:\n",
    "        w_node = size_node.find('width')\n",
    "        h_node = size_node.find('height')\n",
    "        data['width'] = int(w_node.text) if w_node is not None else 0\n",
    "        data['height'] = int(h_node.text) if h_node is not None else 0\n",
    "    else:\n",
    "        data['width'] = 0\n",
    "        data['height'] = 0\n",
    "\n",
    "    # Extract object details\n",
    "    for obj_node in root.findall('object'):\n",
    "        obj_info = {}\n",
    "        name_node = obj_node.find('name')\n",
    "        obj_info['name'] = name_node.text if name_node is not None else \"N/A\"\n",
    "\n",
    "        # Extract bounding box coordinates\n",
    "        bndbox_node = obj_node.find('bndbox')\n",
    "        if bndbox_node is not None:\n",
    "            xmin_node = bndbox_node.find('xmin')\n",
    "            ymin_node = bndbox_node.find('ymin')\n",
    "            xmax_node = bndbox_node.find('xmax')\n",
    "            ymax_node = bndbox_node.find('ymax')\n",
    "\n",
    "            obj_info['xmin'] = float(xmin_node.text) if xmin_node is not None else 0\n",
    "            obj_info['ymin'] = float(ymin_node.text) if ymin_node is not None else 0\n",
    "            obj_info['xmax'] = float(xmax_node.text) if xmax_node is not None else 0\n",
    "            obj_info['ymax'] = float(ymax_node.text) if ymax_node is not None else 0\n",
    "\n",
    "        data['objects'].append(obj_info)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Converts a byte string into a tf.train.Feature of bytes_list.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_list_feature(value):\n",
    "    \"\"\"Converts a float list into a tf.train.Feature of float_list.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Converts an integer value into a tf.train.Feature of int64_list.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _int64_list_feature(value):\n",
    "    \"\"\"Converts a list of integers into a tf.train.Feature of int64_list.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a tf.train.Example from VOC dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voc_dict_to_tfexample(voc_dict, images_folder):\n",
    "    \"\"\"\n",
    "    Takes the dictionary output by parse_voc_xml(xml_file)\n",
    "    along with the folder containing images (images_folder).\n",
    "    \n",
    "    Returns a tf.train.Example with:\n",
    "    - image/encoded\n",
    "    - image/filename\n",
    "    - image/height, image/width\n",
    "    - image/object/bbox/xmin, xmax, ymin, ymax\n",
    "    - image/object/class/text\n",
    "    \"\"\"\n",
    "    filename = voc_dict['filename']\n",
    "    if filename is None:\n",
    "        # If <filename> is missing in the XML, skip this entry\n",
    "        return None\n",
    "\n",
    "    img_path = os.path.join(images_folder, filename)\n",
    "    if not os.path.isfile(img_path):\n",
    "        # If the image does not exist, skip this entry\n",
    "        return None\n",
    "\n",
    "    # Read the image in binary format\n",
    "    with tf.io.gfile.GFile(img_path, 'rb') as fid:\n",
    "        encoded_image = fid.read()\n",
    "\n",
    "    width = voc_dict['width']\n",
    "    height = voc_dict['height']\n",
    "\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    class_texts = []\n",
    "\n",
    "    for obj in voc_dict['objects']:\n",
    "        if width > 0 and height > 0:\n",
    "            # Normalize bounding box coordinates\n",
    "            xmins.append(obj['xmin'] / width)\n",
    "            xmaxs.append(obj['xmax'] / width)\n",
    "            ymins.append(obj['ymin'] / height)\n",
    "            ymaxs.append(obj['ymax'] / height)\n",
    "        else:\n",
    "            # Avoid division by zero if image size is not available\n",
    "            xmins.append(0.0)\n",
    "            xmaxs.append(0.0)\n",
    "            ymins.append(0.0)\n",
    "            ymaxs.append(0.0)\n",
    "\n",
    "        # Encode class name as bytes\n",
    "        class_texts.append(obj['name'].encode('utf8'))\n",
    "\n",
    "    feature_dict = {\n",
    "        'image/encoded': _bytes_feature(encoded_image),\n",
    "        'image/filename': _bytes_feature(filename.encode('utf8')),\n",
    "        'image/format': _bytes_feature(b'jpg'),  # Assuming JPEG format\n",
    "\n",
    "        'image/height': _int64_feature(height),\n",
    "        'image/width': _int64_feature(width),\n",
    "\n",
    "        'image/object/bbox/xmin': _float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': _float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': _float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': _float_list_feature(ymaxs),\n",
    "\n",
    "        # Store class text; could also map to class IDs if needed\n",
    "        'image/object/class/text':\n",
    "            tf.train.Feature(bytes_list=tf.train.BytesList(value=class_texts)),\n",
    "    }\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main conversion function (XML -> TFRecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_voc_to_tfrecord(annotations_folder, images_folder, output_tfrecord):\n",
    "    \"\"\"\n",
    "    Reads all .xml files from 'annotations_folder', pairs them\n",
    "    with images in 'images_folder', and writes a TFRecord to\n",
    "    'output_tfrecord'.\n",
    "\n",
    "    Returns the number of successfully written examples and\n",
    "    the number of errors (e.g. missing files).\n",
    "    \n",
    "    Args:\n",
    "        annotations_folder (str): Directory containing annotation XML files.\n",
    "        images_folder (str): Directory containing image files.\n",
    "        output_tfrecord (str): Path to the output TFRecord file.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (number_of_written_examples, number_of_errors)\n",
    "    \"\"\"\n",
    "    xml_files = glob.glob(os.path.join(annotations_folder, \"*.xml\"))\n",
    "    num_written = 0\n",
    "    num_errors = 0\n",
    "\n",
    "    with tf.io.TFRecordWriter(output_tfrecord) as writer:\n",
    "        for xml_file in xml_files:\n",
    "            voc_info = parse_voc_xml(xml_file)\n",
    "            tf_example = voc_dict_to_tfexample(voc_info, images_folder)\n",
    "            if tf_example is not None:\n",
    "                writer.write(tf_example.SerializeToString())\n",
    "                num_written += 1\n",
    "            else:\n",
    "                num_errors += 1\n",
    "\n",
    "    return num_written, num_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_names(annotations_folder):\n",
    "    \"\"\"\n",
    "    Retrieves a list of image names from the annotation XML files.\n",
    "    \n",
    "    Args:\n",
    "        annotations_folder (str): Directory containing annotation XML files.\n",
    "        \n",
    "    Returns:\n",
    "        list: List of image names without file extensions.\n",
    "    \"\"\"\n",
    "    xml_files = glob.glob(os.path.join(annotations_folder, \"*.xml\"))\n",
    "    image_names = [os.path.splitext(os.path.basename(f))[0] for f in xml_files]\n",
    "    return image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(image_names, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, seed=42):\n",
    "    \"\"\"\n",
    "    Randomly splits the dataset into train, validation, and test sets.\n",
    "    \n",
    "    Args:\n",
    "        image_names (list): List of image names.\n",
    "        train_ratio (float): Proportion of data for training.\n",
    "        val_ratio (float): Proportion of data for validation.\n",
    "        test_ratio (float): Proportion of data for testing.\n",
    "        seed (int): Seed for randomization to ensure reproducibility.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with keys 'train', 'val', 'test' mapping to respective image lists.\n",
    "    \"\"\"\n",
    "    assert train_ratio + val_ratio + test_ratio == 1.0, \"Ratios must sum to 1.0\"\n",
    "    \n",
    "    random.seed(seed)\n",
    "    random.shuffle(image_names)\n",
    "    \n",
    "    total = len(image_names)\n",
    "    train_end = int(train_ratio * total)\n",
    "    val_end = train_end + int(val_ratio * total)\n",
    "    \n",
    "    splits = {\n",
    "        'train': image_names[:train_end],\n",
    "        'val': image_names[train_end:val_end],\n",
    "        'test': image_names[val_end:]\n",
    "    }\n",
    "    \n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfrecord(split, image_list, annotations_folder, images_folder, output_dir):\n",
    "    \"\"\"\n",
    "    Creates a TFRecord file for a specific data split.\n",
    "    \n",
    "    Args:\n",
    "        split (str): Name of the split ('train', 'val', 'test').\n",
    "        image_list (list): List of image names for the split.\n",
    "        annotations_folder (str): Directory containing annotation XML files.\n",
    "        images_folder (str): Directory containing image files.\n",
    "        output_dir (str): Directory where the TFRecord will be saved.\n",
    "        \n",
    "    Returns:\n",
    "        int: Number of examples written to the TFRecord.\n",
    "    \"\"\"\n",
    "    output_path = os.path.join(output_dir, f\"{split}.tfrecord\")\n",
    "    writer = tf.io.TFRecordWriter(output_path)\n",
    "    count = 0\n",
    "    \n",
    "    for image_name in image_list:\n",
    "        xml_path = os.path.join(annotations_folder, f\"{image_name}.xml\")\n",
    "        if not os.path.exists(xml_path):\n",
    "            print(f\"Warning: XML file not found for {image_name}.jpg\")\n",
    "            continue\n",
    "        \n",
    "        voc_dict = parse_voc_xml(xml_path)\n",
    "        tf_example = voc_dict_to_tfexample(voc_dict, images_folder)\n",
    "        if tf_example is not None:\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "            count += 1\n",
    "        else:\n",
    "            print(f\"Warning: Failed to create tf.train.Example for {image_name}.jpg\")\n",
    "    \n",
    "    writer.close()\n",
    "    print(f\"TFRecord for '{split}' created at: {output_path} with {count} examples.\")\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tfrecords(annotations_folder, images_folder, output_dir, \n",
    "                       train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, seed=42):\n",
    "    \"\"\"\n",
    "    Generates TFRecord files for train, validation, and test splits.\n",
    "    \n",
    "    Args:\n",
    "        annotations_folder (str): Directory containing annotation XML files.\n",
    "        images_folder (str): Directory containing image files.\n",
    "        output_dir (str): Directory where TFRecords will be saved.\n",
    "        train_ratio (float): Proportion of data for training.\n",
    "        val_ratio (float): Proportion of data for validation.\n",
    "        test_ratio (float): Proportion of data for testing.\n",
    "        seed (int): Seed for randomization to ensure reproducibility.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Created output directory at: {output_dir}\")\n",
    "    \n",
    "    # Get all image names\n",
    "    image_names = get_image_names(annotations_folder)\n",
    "    print(f\"Total images found: {len(image_names)}\")\n",
    "    \n",
    "    # Split the dataset\n",
    "    splits = split_dataset(image_names, train_ratio, val_ratio, test_ratio, seed)\n",
    "    \n",
    "    for split, images in splits.items():\n",
    "        print(f\"Creating TFRecord for '{split}' with {len(images)} examples.\")\n",
    "        create_tfrecord(split, images, annotations_folder, images_folder, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demostration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your directories\n",
    "annotations_dir = \"../data/Annotations\"       # Path to Annotations directory\n",
    "images_dir = \"../data/JPEGImages\"             # Path to JPEGImages directory\n",
    "output_dir = \"../data/TFRecords\"              # Path to output TFRecords directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images found: 20\n",
      "Creating TFRecord for 'train' with 14 examples.\n",
      "TFRecord for 'train' created at: ../data/TFRecords\\train.tfrecord with 14 examples.\n",
      "Creating TFRecord for 'val' with 3 examples.\n",
      "TFRecord for 'val' created at: ../data/TFRecords\\val.tfrecord with 3 examples.\n",
      "Creating TFRecord for 'test' with 3 examples.\n",
      "TFRecord for 'test' created at: ../data/TFRecords\\test.tfrecord with 3 examples.\n"
     ]
    }
   ],
   "source": [
    "# Generate the TFRecords with train, val, and test splits\n",
    "generate_tfrecords(\n",
    "    annotations_folder=annotations_dir,\n",
    "    images_folder=images_dir,\n",
    "    output_dir=output_dir,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding TFRecord Structure\n",
    "\n",
    "A **TFRecord** file is a **binary container** that stores a sequence of data records. In typical TensorFlow pipelines, each record is encoded as a [`tf.train.Example`](https://www.tensorflow.org/api_docs/python/tf/train/Example). Below is an overview of how these components are organized and why they matter.\n",
    "\n",
    "\n",
    "\n",
    "## 1. TFRecord as a File Format\n",
    "\n",
    "- **TFRecord** is essentially a stream of serialized protocol buffer messages, each message representing one “data example.”  \n",
    "- This format is efficient for reading large datasets, especially during training on GPUs or TPUs, because it avoids the overhead of handling many small files.\n",
    "\n",
    "In other words, you can think of a TFRecord file as “**N** examples concatenated in binary,” where each example is encoded with a protocol buffer schema.\n",
    "\n",
    "\n",
    "\n",
    "## 2. `tf.train.Example` Messages\n",
    "\n",
    "Within each record inside a TFRecord file, we typically store data in a structure called **`tf.train.Example`**. Conceptually:\n",
    "\n",
    "1. **`Example`** is the top-level message that groups a set of “features.”\n",
    "2. **`Features`** is a container, a map from string keys to `Feature` values.\n",
    "3. **`Feature`** is a union-type message that holds data in one of three lists:\n",
    "   - **BytesList** (for binary data such as raw image bytes or strings)\n",
    "   - **FloatList** (for floating-point values)\n",
    "   - **Int64List** (for integer values)\n",
    "\n",
    "The important takeaway is that each “feature” in an `Example` is identified by a **key** (a string) and can store either bytes, floats, or integers in list form.\n",
    "\n",
    "\n",
    "\n",
    "## 3. The `Feature` Hierarchy\n",
    "\n",
    "To visualize the hierarchy:\n",
    "\n",
    "```plaintext\n",
    "\n",
    "Example \n",
    "   └─ Features \n",
    "         └─ feature \n",
    "               ├─ \"some_key\" → Feature (bytes_list) \n",
    "               ├─ \"another_key\" → Feature (int64_list) \n",
    "               └─ \"third_key\" → Feature (float_list)\n",
    "\n",
    "```\n",
    "\n",
    "### Components Explained:\n",
    "\n",
    "1. **Example**\n",
    "   - **Description**: The top-level message that represents a single data record.\n",
    "   - **Role**: Encapsulates all the features associated with that specific instance (e.g., one image and its annotations).\n",
    "\n",
    "2. **Features**\n",
    "   - **Description**: A container within `Example` that holds multiple feature entries.\n",
    "   - **Role**: Acts as a map (dictionary) where each key is a string representing the feature name, and each value is a `Feature` object.\n",
    "\n",
    "3. **feature**\n",
    "   - **Description**: Each entry within the `Features` map.\n",
    "   - **Role**: Associates a feature name (key) with its corresponding data (value).\n",
    "\n",
    "4. **\"some_key\" → Feature (bytes_list)**\n",
    "   - **Key**: `\"some_key\"`\n",
    "   - **Value**: A `Feature` containing a list of bytes.\n",
    "   - **Use Case**: Typically used for binary data such as encoded images or serialized objects.\n",
    "\n",
    "5. **\"another_key\" → Feature (int64_list)**\n",
    "   - **Key**: `\"another_key\"`\n",
    "   - **Value**: A `Feature` containing a list of 64-bit integers.\n",
    "   - **Use Case**: Often used for categorical labels or counts.\n",
    "\n",
    "6. **\"third_key\" → Feature (float_list)**\n",
    "   - **Key**: `\"third_key\"`\n",
    "   - **Value**: A `Feature` containing a list of floating-point numbers.\n",
    "   - **Use Case**: Commonly used for numerical features like bounding box coordinates or measurement values.\n",
    "\n",
    "\n",
    "## Detailed Breakdown\n",
    "\n",
    "### 1. `tf.train.Example`\n",
    "\n",
    "- **Purpose**: Encapsulates all the data for a single instance in your dataset.\n",
    "- **Structure**:\n",
    "  - **Features**: Contains all the individual data points (features) related to that instance.\n",
    "\n",
    "### 2. `Features`\n",
    "\n",
    "- **Purpose**: Acts as a container mapping feature names to their data.\n",
    "- **Structure**:\n",
    "  - **feature**: Each entry maps a feature name (string) to a `Feature` object.\n",
    "\n",
    "### 3. `Feature`\n",
    "\n",
    "- **Purpose**: Represents the actual data associated with a feature name.\n",
    "- **Types**:\n",
    "  - **BytesList**: For binary data (e.g., images, serialized data).\n",
    "  - **FloatList**: For floating-point numbers.\n",
    "  - **Int64List**: For integer values.\n",
    "\n",
    "\n",
    "## Common structure in Object Detection\n",
    "\n",
    "Here's a common visualization of the TFRecord hierarchy for object detection:\n",
    "\n",
    "```plaintext\n",
    "Example \n",
    "  └─ Features \n",
    "        └─ feature \n",
    "              ├─ \"image/encoded\" → Feature (bytes_list) \n",
    "              ├─ \"image/height\" → Feature (int64_list) \n",
    "              ├─ \"image/width\" → Feature (int64_list) \n",
    "              ├─ \"bbox/xmin\" → Feature (float_list) \n",
    "              ├─ \"bbox/ymin\" → Feature (float_list) \n",
    "              ├─ \"bbox/xmax\" → Feature (float_list) \n",
    "              ├─ \"bbox/ymax\" → Feature (float_list) \n",
    "              └─ \"label\" → Feature (int64_list)\n",
    "```\n",
    "\n",
    "- **\"image/encoded\"**: Stores the raw image bytes.\n",
    "- **\"image/height\" & \"image/width\"**: Store the dimensions of the image.\n",
    "- **\"bbox/xmin\", \"bbox/ymin\", \"bbox/xmax\", \"bbox/ymax\"**: Store the bounding box coordinates, typically normalized between 0 and 1.\n",
    "- **\"label\"**: Stores the class label as an integer.\n",
    "\n",
    "\n",
    "\n",
    "## 4. Summary\n",
    "\n",
    "- **A TFRecord file**: A collection of **serialized `Example`** messages.  \n",
    "- **`tf.train.Example`**: Defines how each record’s data is organized (through a features map).  \n",
    "- **`Feature`**: The building block that stores a list of bytes, floats, or int64s.  \n",
    "- **Efficiency & Flexibility**: By encapsulating data in this manner, you can handle images, text, numerical arrays, and more, all in a single format conducive to large-scale machine learning.\n",
    "\n",
    "Overall, TFRecord and `tf.train.Example` are core tools in TensorFlow to package and process data efficiently.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity-Check of TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_tfrecord(tfrecord_path, max_samples=4):\n",
    "    \"\"\"\n",
    "    Inspects and prints a specified number of examples from a TFRecord file.\n",
    "    \n",
    "    Args:\n",
    "        tfrecord_path (str): Path to the TFRecord file.\n",
    "        max_samples (int): Number of examples to inspect.\n",
    "    \"\"\"\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "    for raw_record in dataset.take(max_samples):\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "        print(example)\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the generated TFRecords\n",
    "print(\"\\nInspecting Train TFRecord:\")\n",
    "train_tfrecord_path = os.path.join(output_dir, \"train.tfrecord\")\n",
    "inspect_tfrecord(train_tfrecord_path, max_samples=2)\n",
    "\n",
    "print(\"\\nInspecting Validation TFRecord:\")\n",
    "val_tfrecord_path = os.path.join(output_dir, \"val.tfrecord\")\n",
    "inspect_tfrecord(val_tfrecord_path, max_samples=2)\n",
    "\n",
    "print(\"\\nInspecting Test TFRecord:\")\n",
    "test_tfrecord_path = os.path.join(output_dir, \"test.tfrecord\")\n",
    "inspect_tfrecord(test_tfrecord_path, max_samples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satellite-object-detection-preprocessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
