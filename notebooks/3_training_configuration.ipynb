{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.- Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import tarfile\n",
    "import re\n",
    "from git import Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, destination_folder, file_name):\n",
    "\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "    path_to_write = f\"{destination_folder}/{file_name}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        with open(path_to_write, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"File downloaded and saved to: {path_to_write}\")\n",
    "    else:\n",
    "        print(f\"Failed to download the file, status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model = 'ssd-mobilenet-v2-fpnlite-320'\n",
    "\n",
    "MODELS_CONFIG = {\n",
    "    'ssd-mobilenet-v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
    "        'base_pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n",
    "    },\n",
    "    'efficientdet-d0': {\n",
    "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
    "        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n",
    "    },\n",
    "    'ssd-mobilenet-v2-fpnlite-320': {\n",
    "        'model_name': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8',\n",
    "        'base_pipeline_file': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz',\n",
    "    },\n",
    "}\n",
    "\n",
    "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
    "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
    "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
    "destination_folder = \"../train/pretrained_models\"\n",
    "model_file_name = f\"{chosen_model}.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved to: ../train/pretrained_models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n"
     ]
    }
   ],
   "source": [
    "download_file(download_tar, destination_folder, model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = tarfile.open(f\"{destination_folder}/{model_file_name}\")\n",
    "tar.extractall(path = destination_folder)\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Model Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_config = f\"https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/{model_name}.config\"\n",
    "config_file_name = f\"{model_name}.config\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved to: ../train/pretrained_models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config\n"
     ]
    }
   ],
   "source": [
    "download_file(url_config, destination_folder, config_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone Github Tensorflow Models Garden Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_repository(repo_url, local_dir):\n",
    "    # Create the local directory if it does not exist\n",
    "    if not os.path.exists(local_dir):\n",
    "        os.makedirs(local_dir)\n",
    "        print(f\"Directory '{local_dir}' created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{local_dir}' already exists.\")\n",
    "    \n",
    "    # Clone the repository into the specified directory\n",
    "    try:\n",
    "        print(f\"Cloning {repo_url} into {local_dir}\")\n",
    "        Repo.clone_from(repo_url, local_dir)\n",
    "        print(\"Repository successfully cloned.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to clone the repository: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the GitHub repository you want to clone\n",
    "repo_url = 'https://github.com/tensorflow/models.git'\n",
    "\n",
    "# Local path where you want to save the cloned repository\n",
    "train_code = '../train/src/'\n",
    "\n",
    "# Execute the function\n",
    "clone_repository(repo_url, train_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters in Config Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def update_pipeline_config(pipeline_path, output_path, fine_tune_checkpoint, train_record, val_record, \n",
    "                           label_map, batch_size, num_steps, num_classes, chosen_model):\n",
    "    \"\"\"\n",
    "    Updates a TensorFlow Object Detection API pipeline configuration file with custom values.\n",
    "\n",
    "    Parameters:\n",
    "    - pipeline_path (str): Path to the original pipeline.config file.\n",
    "    - output_path (str): Path where the updated config file should be saved.\n",
    "    - fine_tune_checkpoint (str): Path to the fine-tune checkpoint.\n",
    "    - train_record (str): Path to the training TFRecord file.\n",
    "    - val_record (str): Path to the validation TFRecord file.\n",
    "    - label_map (str): Path to the label map file.\n",
    "    - batch_size (int): Training batch size.\n",
    "    - num_steps (int): Number of training steps.\n",
    "    - num_classes (int): Number of classes in the dataset.\n",
    "    - chosen_model (str): Model type (e.g., 'ssd-mobilenet-v2', 'efficientdet-d0').\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    print(\"Writing custom configuration file...\")\n",
    "\n",
    "    # Ensure the destination directory exists\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    with open(pipeline_path, 'r') as f:\n",
    "        config_content = f.read()\n",
    "    \n",
    "    # Update fine-tune checkpoint path\n",
    "    config_content = re.sub(r'fine_tune_checkpoint: \".*?\"', \n",
    "                            f'fine_tune_checkpoint: \"{fine_tune_checkpoint}\"', config_content)\n",
    "    \n",
    "    # Update TFRecord paths\n",
    "    config_content = re.sub(r'(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', \n",
    "                            f'input_path: \"{train_record}\"', config_content)\n",
    "    config_content = re.sub(r'(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', \n",
    "                            f'input_path: \"{val_record}\"', config_content)\n",
    "    \n",
    "    # Update label map path\n",
    "    config_content = re.sub(r'label_map_path: \".*?\"', \n",
    "                            f'label_map_path: \"{label_map}\"', config_content)\n",
    "    \n",
    "    # Update batch size\n",
    "    config_content = re.sub(r'batch_size: \\d+', \n",
    "                            f'batch_size: {batch_size}', config_content)\n",
    "    \n",
    "    # Update training steps\n",
    "    config_content = re.sub(r'num_steps: \\d+', \n",
    "                            f'num_steps: {num_steps}', config_content)\n",
    "    \n",
    "    # Update number of classes\n",
    "    config_content = re.sub(r'num_classes: \\d+', \n",
    "                            f'num_classes: {num_classes}', config_content)\n",
    "    \n",
    "    # Change fine-tune checkpoint type to 'detection'\n",
    "    config_content = re.sub(r'fine_tune_checkpoint_type: \"classification\"', \n",
    "                            'fine_tune_checkpoint_type: \"detection\"', config_content)\n",
    "    \n",
    "    # Adjust learning rate if using ssd-mobilenet-v2\n",
    "    if chosen_model == 'ssd-mobilenet-v2':\n",
    "        config_content = re.sub(r'learning_rate_base: .8', 'learning_rate_base: .08', config_content)\n",
    "        config_content = re.sub(r'warmup_learning_rate: 0.13333', 'warmup_learning_rate: .026666', config_content)\n",
    "    \n",
    "    # Adjust resizer settings if using efficientdet-d0 (for TFLite compatibility)\n",
    "    if chosen_model == 'efficientdet-d0':\n",
    "        config_content = re.sub(r'keep_aspect_ratio_resizer', 'fixed_shape_resizer', config_content)\n",
    "        config_content = re.sub(r'pad_to_max_dimension: true', '', config_content)\n",
    "        config_content = re.sub(r'min_dimension', 'height', config_content)\n",
    "        config_content = re.sub(r'max_dimension', 'width', config_content)\n",
    "    \n",
    "    # Save updated config file\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(config_content)\n",
    "    \n",
    "    print(f\"Updated pipeline configuration saved to: {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_path = destination_folder + '/' + base_pipeline_file\n",
    "output_path = '../train/config_files/local_config_file.config'\n",
    "fine_tune_checkpoint = '/app/train/pretrained_models/' + model_name + '/checkpoint/ckpt-0'\n",
    "train_record = '/app/data/TFRecords/train.tfrecord'\n",
    "val_record = '/app/data/TFRecords/val.tfrecord'\n",
    "label_map = '/app/data/TFRecords/label_map.pbtxt'\n",
    "batch_size = 1\n",
    "num_steps = 1\n",
    "num_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing custom configuration file...\n",
      "Updated pipeline configuration saved to: ../train/config_files/local_config_file.config\n"
     ]
    }
   ],
   "source": [
    "update_pipeline_config(pipeline_path,\n",
    "                       output_path,\n",
    "                       fine_tune_checkpoint,\n",
    "                       train_record,\n",
    "                       val_record,\n",
    "                       label_map,\n",
    "                       batch_size,\n",
    "                       num_steps,\n",
    "                       num_classes,\n",
    "                       chosen_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satellite-object-detection-train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
